{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thiagorjes/DeepVGL/blob/main/DeepVGL_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0ADo9cWnVp3"
   },
   "source": [
    "# **Execute os passos descritos em:**\n",
    "https://github.com/LCAD-UFES/carmen_lcad/blob/master/src/deep_vgl/treino.md\n",
    "\n",
    "# Usando os arquivos gerados no processo descrito no link acima, você pode treinar a DARKNET nas etapas a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MllDlArMQ7H8"
   },
   "source": [
    "# A implementação da Darknet19 é parte da framework **lightnet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLKUtR6AI0BA"
   },
   "source": [
    "# **1 - Instalar as dependências**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K3PuJpKcIJS4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached https://files.pythonhosted.org/packages/dd/b9/824df420f6abf551e41bbaacbaa0be8321dc104f9f3803051513844dc310/torch-1.8.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting dataclasses; python_version < \"3.7\" (from torch)\n",
      "  Using cached https://files.pythonhosted.org/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl\n",
      "Collecting typing-extensions (from torch)\n",
      "  Using cached https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n",
      "Collecting numpy (from torch)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/b2/6c7545bb7a38754d63048c7696804a0d947328125d81bf12beaa692c3ae3/numpy-1.19.5-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Installing collected packages: dataclasses, typing-extensions, numpy, torch\n",
      "Successfully installed dataclasses-0.8 numpy-1.19.5 torch-1.8.1 typing-extensions-3.7.4.3\n",
      "Collecting torchvision\n",
      "  Using cached https://files.pythonhosted.org/packages/74/a0/4bfa036c5b88444e95d0b3b24c6e0d6047b9c5920572c4be3135e24f15ba/torchvision-0.9.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting torch==1.8.1 (from torchvision)\n",
      "  Using cached https://files.pythonhosted.org/packages/dd/b9/824df420f6abf551e41bbaacbaa0be8321dc104f9f3803051513844dc310/torch-1.8.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pillow>=4.1.1 (from torchvision)\n",
      "  Using cached https://files.pythonhosted.org/packages/89/d2/942af29f8494a1a3f4bc4f483d520f7c02ccae677f5f50cf76c6b3d827d8/Pillow-8.2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numpy (from torchvision)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/b2/6c7545bb7a38754d63048c7696804a0d947328125d81bf12beaa692c3ae3/numpy-1.19.5-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting typing-extensions (from torch==1.8.1->torchvision)\n",
      "  Using cached https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n",
      "Collecting dataclasses; python_version < \"3.7\" (from torch==1.8.1->torchvision)\n",
      "  Using cached https://files.pythonhosted.org/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl\n",
      "Installing collected packages: typing-extensions, numpy, dataclasses, torch, pillow, torchvision\n",
      "Successfully installed dataclasses-0.8 numpy-1.19.5 pillow-8.2.0 torch-1.8.1 torchvision-0.9.1 typing-extensions-3.7.4.3\n",
      "Collecting GPUtil\n",
      "Installing collected packages: GPUtil\n",
      "Successfully installed GPUtil-1.4.0\n",
      "Collecting lightnet\n",
      "  Using cached https://files.pythonhosted.org/packages/98/af/aa6f022cc517dbf215215507b197910e916444c5d27a83125ee23af861fb/lightnet-2.0.1-py3-none-any.whl\n",
      "Collecting brambox>=2 (from lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/f8/86707121ae54934a7c8530b83d1d86e70f1ee04c5ce08917ce91d79227d8/brambox-3.2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting torch (from lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/dd/b9/824df420f6abf551e41bbaacbaa0be8321dc104f9f3803051513844dc310/torch-1.8.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numpy (from lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/b2/6c7545bb7a38754d63048c7696804a0d947328125d81bf12beaa692c3ae3/numpy-1.19.5-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pillow (from lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/89/d2/942af29f8494a1a3f4bc4f483d520f7c02ccae677f5f50cf76c6b3d827d8/Pillow-8.2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting torchvision (from lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/74/a0/4bfa036c5b88444e95d0b3b24c6e0d6047b9c5920572c4be3135e24f15ba/torchvision-0.9.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting scipy (from brambox>=2->lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting tqdm>=4.27 (from brambox>=2->lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/72/8a/34efae5cf9924328a8f34eeb2fdaae14c011462d9f0e3fcded48e1266d1c/tqdm-4.60.0-py2.py3-none-any.whl\n",
      "Collecting pandas>=1.0 (from brambox>=2->lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/e2/00cacecafbab071c787019f00ad84ca3185952f6bb9bca9550ed83870d4d/pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting typing-extensions (from torch->lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/60/7a/e881b5abb54db0e6e671ab088d079c57ce54e8a01a3ca443f561ccadb37e/typing_extensions-3.7.4.3-py3-none-any.whl\n",
      "Collecting dataclasses; python_version < \"3.7\" (from torch->lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/fe/ca/75fac5856ab5cfa51bbbcefa250182e50441074fdc3f803f6e76451fab43/dataclasses-0.8-py3-none-any.whl\n",
      "Collecting pytz>=2017.2 (from pandas>=1.0->brambox>=2->lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/70/94/784178ca5dd892a98f113cdd923372024dc04b8d40abe77ca76b5fb90ca6/pytz-2021.1-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.7.3 (from pandas>=1.0->brambox>=2->lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting six>=1.5 (from python-dateutil>=2.7.3->pandas>=1.0->brambox>=2->lightnet)\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Installing collected packages: numpy, scipy, tqdm, pytz, six, python-dateutil, pandas, brambox, typing-extensions, dataclasses, torch, pillow, torchvision, lightnet\n",
      "Successfully installed brambox-3.2.0 dataclasses-0.8 lightnet-2.0.1 numpy-1.19.5 pandas-1.1.5 pillow-8.2.0 python-dateutil-2.8.1 pytz-2021.1 scipy-1.5.4 six-1.15.0 torch-1.8.1 torchvision-0.9.1 tqdm-4.60.0 typing-extensions-3.7.4.3\n",
      "Collecting scikit-image\n",
      "  Using cached https://files.pythonhosted.org/packages/0e/ba/53e1bfbdfd0f94514d71502e3acea494a8b4b57c457adbc333ef386485da/scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting tifffile>=2019.7.26 (from scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/42/6b/93a8ee61c6fbe20fa9c17928bd3b80484902b7fd454cecaffba42f5052cb/tifffile-2020.9.3-py3-none-any.whl\n",
      "Collecting numpy>=1.15.1 (from scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/b2/6c7545bb7a38754d63048c7696804a0d947328125d81bf12beaa692c3ae3/numpy-1.19.5-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting scipy>=1.0.1 (from scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting matplotlib!=3.0.0,>=2.0.0 (from scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/09/03/b7b30fa81cb687d1178e085d0f01111ceaea3bf81f9330c937fb6f6c8ca0/matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/59/bb/d2b85265ec9fa3c1922210c9393d4cdf7075cc87cce6fe671d7455f80fbc/PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting imageio>=2.3.0 (from scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/6e/57/5d899fae74c1752f52869b613a8210a2480e1a69688e65df6cb26117d45d/imageio-2.9.0-py3-none-any.whl\n",
      "Collecting networkx>=2.0 (from scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/f3/b7/c7f488101c0bb5e4178f3cde416004280fd40262433496830de8a8c21613/networkx-2.5.1-py3-none-any.whl\n",
      "Collecting pillow!=7.1.0,!=7.1.1,>=4.3.0 (from scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/89/d2/942af29f8494a1a3f4bc4f483d520f7c02ccae677f5f50cf76c6b3d827d8/Pillow-8.2.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib!=3.0.0,>=2.0.0->scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/1b/cbd8ae738719b5f41592a12057ef5442e2ed5f5cb5451f8fc7e9f8875a1a/kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting python-dateutil>=2.1 (from matplotlib!=3.0.0,>=2.0.0->scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.0.0,>=2.0.0->scikit-image)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 (from matplotlib!=3.0.0,>=2.0.0->scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/8a/bb/488841f56197b13700afd5658fc279a2025a39e22449b7cf29864669b15d/pyparsing-2.4.7-py2.py3-none-any.whl\n",
      "Collecting decorator<5,>=4.3 (from networkx>=2.0->scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/ed/1b/72a1821152d07cf1d8b6fce298aeb06a7eb90f4d6d41acec9861e7cc6df0/decorator-4.4.2-py2.py3-none-any.whl\n",
      "Collecting six>=1.5 (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image)\n",
      "  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\n",
      "Installing collected packages: numpy, tifffile, scipy, kiwisolver, six, python-dateutil, cycler, pyparsing, pillow, matplotlib, PyWavelets, imageio, decorator, networkx, scikit-image\n",
      "Successfully installed PyWavelets-1.1.1 cycler-0.10.0 decorator-5.0.7 imageio-2.9.0 kiwisolver-1.3.1 matplotlib-3.3.4 networkx-2.5.1 numpy-1.19.5 pillow-8.2.0 pyparsing-2.4.7 python-dateutil-2.8.1 scikit-image-0.17.2 scipy-1.5.4 six-1.15.0 tifffile-2020.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install torchvision\n",
    "!pip3 install GPUtil\n",
    "!pip3 install lightnet\n",
    "!pip3 install scikit-image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOB208GXH4BE"
   },
   "source": [
    "# **2 - Definição da rede**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nypKQyhXH169",
    "outputId": "9582685f-39e7-4237-8486-b044ed0da096"
   },
   "outputs": [],
   "source": [
    "import lightnet as ln\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import brambox as bb\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# Settings\n",
    "ln.logger.setConsoleLevel('ERROR')             # Only show error log messages\n",
    "bb.logger.setConsoleLevel('ERROR')    \n",
    "\n",
    "import lightnet as ln\n",
    "import torch\n",
    "\n",
    "__all__ = ['params']\n",
    "\n",
    "def load_classes(labels_list):\n",
    "    labels=[]\n",
    "    with open(labels_list) as file:\n",
    "        labels = [line.strip().replace('B','').replace('E','') for line in file]\n",
    "    return labels\n",
    "\n",
    "\n",
    "params = ln.engine.HyperParameters( \n",
    "    # Network\n",
    "    class_label_map = load_classes('../labels_3_1.txt'),\n",
    "    _input_dimension = (448, 448),\n",
    "    _batch_size = 128,\n",
    "    _mini_batch_size = 1,\n",
    "    _max_batches = 40545,\n",
    "\n",
    "    # Loss\n",
    "    _coord_scale = 1.0,\n",
    "    _object_scale = 5.0,\n",
    "    _noobject_scale = 1.0,\n",
    "    _class_scale = 1.0,\n",
    "\n",
    "    # Dataset\n",
    "    _train_set = '/dados/ufes/train.list',\n",
    "    _val_set = '/dados/ufes/valid.list',\n",
    "    _filter_anno = 'ignore',\n",
    "\n",
    "    # Data Augmentation\n",
    "    _jitter = .3,\n",
    "    # _flip = .5,\n",
    "    _angle = 7,\n",
    "    _hue = .1,\n",
    "    _saturation = .75,\n",
    "    # _value = .75,\n",
    ")\n",
    "\n",
    "# Network\n",
    "def init_weights(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight, nonlinearity='leaky_relu')\n",
    "\n",
    "def new_network(class_label_map):\n",
    "    params.network = ln.models.Darknet19(len(class_label_map))\n",
    "    params.network.apply(init_weights)\n",
    "    params.loss = nn.CrossEntropyLoss()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaAX_bzDK1Ly"
   },
   "source": [
    "# **3 - Definir o dataset loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "py7dSwClK7DY"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import logging\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms as tf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Any, Callable, Dict, IO, List, Optional, Tuple, Union\n",
    "import lightnet as ln\n",
    "import re\n",
    "from skimage import io, transform\n",
    "\n",
    "__all__ = ['VoltaDaUfes']\n",
    "log = logging.getLogger('lightnet.VoltaDaUfes.dataset')\n",
    "\n",
    "class VoltaDaUfes(Dataset):\n",
    "    \"\"\" VoltaDaUfes Dataset \"\"\"\n",
    "\n",
    "    def __init__(self, image_list, params, augment):\n",
    "        \n",
    "        # Data transformation pipeline\n",
    "        if augment:\n",
    "            transform = ln.data.transform.Compose([\n",
    "                lambda img: img.convert('RGB'),\n",
    "                ln.data.transform.RandomHSV(params.hue, params.saturation, params.value),\n",
    "                ln.data.transform.RandomJitter(params.jitter, fill_color=0),\n",
    "                ln.data.transform.RandomRotate(params.angle),\n",
    "                ln.data.transform.Letterbox(dataset=self, fill_color=0),\n",
    "                ln.data.transform.FitAnno(),\n",
    "                tf.ToTensor(),\n",
    "            ])\n",
    "        else:\n",
    "            transform = ln.data.transform.Compose([\n",
    "                lambda img: img,\n",
    "                tf.ToTensor(),\n",
    "            ])\n",
    "        with open(image_list) as file:\n",
    "            self.image_list = [line.strip() for line in file]\n",
    "        self.county=len(self.image_list)        \n",
    "        self.transform = transform\n",
    "        self.params = params\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.county\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[Any, Any]:\n",
    "        img_name = self.image_list[idx]\n",
    "        image = io.imread(img_name)\n",
    "        class_id = int(img_name.split(\"_\")[-1].split(\".\")[-2].replace('B','').replace('E',''))\n",
    "        if self.transform:\n",
    "            sample = self.transform(image)\n",
    "\n",
    "        return sample,class_id        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjRRJwKQLPNi"
   },
   "source": [
    "# **4 - Definir a classe principal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iO5EiXnULVd5",
    "outputId": "60afe8d2-e94a-4c40-fe9b-15e3b267bcac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-b BATCH_SIZE] [-d SUBDIVISIONS]\n",
      "                             [-e EPOCHS] [-r LEARNING_RATE] [-j JITTER]\n",
      "                             [-a ANGLE] [-v VALUE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/thiago/.local/share/jupyter/runtime/kernel-e26c83d7-c3ce-4833-9808-d2e40b585858.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "from statistics import mean\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import lightnet as ln\n",
    "import brambox as bb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "log = logging.getLogger('lightnet.VoltaDaUfes.test')\n",
    "\n",
    "\n",
    "# TODO : refactor this to a simple set of functions, as it is overkill to create this class.\n",
    "class DarknetEngine:\n",
    "    def __init__(self, params, test_loader,train_loader, **kwargs):\n",
    "        self.params = params\n",
    "        self.test_loader = test_loader\n",
    "        self.train_loader = train_loader\n",
    "\n",
    "        self.network = params.network\n",
    "        self.train_loss = []\n",
    "        # Setting kwargs\n",
    "        for k, v in kwargs.items():\n",
    "            if not hasattr(self, k):\n",
    "                setattr(self, k, v)\n",
    "            else:\n",
    "                log.error('{k} attribute already exists on TestEngine, not overwriting with `{v}`')\n",
    "\n",
    "    def __call__(self):\n",
    "        self.params.to(self.device)\n",
    "        self.network.eval()\n",
    "\n",
    "    def train(self,epochs,log_interval):\n",
    "        params.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(params.optimizer, len(self.train_loader))\n",
    "        val = params.steps\n",
    "        for epoch in range(epochs):\n",
    "            if epoch>0 and epoch % val == 0:\n",
    "                val = val + val*params.multiply_sgdr\n",
    "                total = val * len(self.train_loader)\n",
    "                params.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(params.optimizer, total)    \n",
    "            self.train_epoch(log_interval,epoch,val)\n",
    "            self.test()\n",
    "            if epoch>0 and epoch % 1 == 0:\n",
    "                self.params.save(os.path.join('backup', f'deepvgl_{epoch}.state.pt'))\n",
    "                self.params.network.save(os.path.join('backup', f'deepvgl_{epoch}.state.weights'))\n",
    "\n",
    "    def train_epoch(self,log_interval,epoch,step):\n",
    "        params.network.train()\n",
    "        local_loss = 0\n",
    "        for batch_idx,(data, target) in enumerate((self.train_loader)):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            params.optimizer.step()\n",
    "            params.optimizer.zero_grad()\n",
    "            output = self.network(data)\n",
    "            loss_temp = self.params.loss(output, target)\n",
    "            loss_temp.backward()\n",
    "            self.train_loss.append(loss_temp.item())\n",
    "            if ((batch_idx+1) * params.mini_batch_size) % params.batch_size == 0:\n",
    "                local_loss = mean(self.train_loss[-args.subdivisions:])\n",
    "                self.train_loss = []\n",
    "            real_batch_id = ((batch_idx+1) * params.mini_batch_size) / params.batch_size\n",
    "            if real_batch_id>0 and real_batch_id % log_interval == 0:\n",
    "                print('Train Epoch: {} [{:5d}/{} ({:.0f}%)]\\tLoss: {:.6f}  \\tLearning Rate: {:.6f}'.format(\n",
    "                    epoch, (batch_idx+1) * len(data), len(self.train_loader.dataset),\n",
    "                    100. * batch_idx / len(self.train_loader), \n",
    "                    local_loss,\n",
    "                    params.scheduler.get_last_lr()[0]))\n",
    "            params.scheduler.step()\n",
    "\n",
    "\n",
    "    def test(self):\n",
    "        pred, label = [],[]\n",
    "        images, labels = next(iter(self.test_loader))\n",
    "        counter = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.test_loader:\n",
    "                data = data.to(self.device)\n",
    "                output = self.network(data)\n",
    "                probs=nn.Softmax(dim=1)\n",
    "                softmax_out = probs(output)\n",
    "                counter+=1\n",
    "                print(counter)\n",
    "                dvgl = (softmax_out.argmax(dim=1))\n",
    "                pred.append(dvgl)\n",
    "                label.append(target)\n",
    "\n",
    "        print(\"deep_vgl\\tGT\\tMAE0\\tMAE1\\tMAE2\")\n",
    "        MAE = np.zeros(3)\n",
    "        for (dvgl,gt) in zip(pred,label):\n",
    "            \n",
    "            if abs(dvgl[0].item() - gt[0].item()) == 0:\n",
    "                MAE[0]=MAE[0]+1\n",
    "                MAE[1]=MAE[1]+1\n",
    "                MAE[2]=MAE[2]+1\n",
    "            if abs(dvgl[0].item() - gt[0].item()) == 1:\n",
    "                MAE[1]=MAE[1]+1\n",
    "                MAE[2]=MAE[2]+1\n",
    "            if abs(dvgl[0].item() - gt[0].item()) == 2:\n",
    "                MAE[2]=MAE[2]+1\n",
    "            \n",
    "            print(dvgl[0].item(),\"\\t\\t\",gt[0].item(),\"\\t\", MAE[0], MAE[1], MAE[2] )\n",
    "\n",
    "        MAE = 100*MAE/(self.test_loader.__len__())\n",
    "        print(\"MAE0\\tMAE1\\tMAE2\")\n",
    "        print(\"%2.1f\" % MAE[0], \"\\t%2.2f\" % MAE[1], \"\\t%2.2f\" % MAE[2] )\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Test trained network',\n",
    "    formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    ")\n",
    "# parser.add_argument('initial_weight', help='Path to initial weights file')\n",
    "# parser.add_argument('-n', '--network', help='network config file', required=True)\n",
    "# parser.add_argument('-c', '--cuda', help='Use cuda', action='store_true')\n",
    "# parser.add_argument('-l', '--labels', help='labels file', required=True)\n",
    "parser.add_argument('-b','--batch_size', type=int, default=128, help='input batch size for training (default: 64)')\n",
    "parser.add_argument('-d','--subdivisions', type=int, default=16, help='input batch subdivisions (default: 16)')\n",
    "parser.add_argument('-e','--epochs', type=int, default=130, help='number of epochs to train (default: 130)')\n",
    "parser.add_argument('-r','--learning_rate', type=float, default=0.0001, help='learning rate (default: 0.001)')\n",
    "parser.add_argument('-j','--jitter', type=float, default=0.3, help='jitter (default: 0.3)')\n",
    "parser.add_argument('-a','--angle', type=float, default=7, help='random angle (default: 7)')\n",
    "parser.add_argument('-v','--value', type=float, default=1.5, help='HSV value (default: 1.5)')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "weights = '/dados/darknet/darknet19_448.conv.23'\n",
    "labels = '/dados/ufes/labels_3_1.txt'\n",
    "# Parse arguments\n",
    "device = torch.device('cpu')\n",
    "validation=True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    log.debug('CUDA enabled')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    log.error('CUDA not available')\n",
    "\n",
    "\n",
    "#params = ln.engine.HyperParameters.from_file(args.network)\n",
    "new_network(load_classes(labels))\n",
    "params = params\n",
    "params.class_label_map = load_classes(labels)\n",
    "params.batch_size = args.batch_size\n",
    "params.mini_batch_size=int(args.batch_size/args.subdivisions)\n",
    "print(repr(params.network))\n",
    "if weights is not None:\n",
    "    if weights.endswith('.state.pt'):\n",
    "        params.load(weights)\n",
    "    else:\n",
    "        params.network.load(weights, strict=False)\n",
    "#params.network.load(args.initial_weight)\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "params.optimizer = torch.optim.SGD(\n",
    "    params.network.parameters(),\n",
    "    lr = args.learning_rate,\n",
    "    momentum = 0.9,\n",
    "    weight_decay = .0005\n",
    ")\n",
    "params.multiply_sgdr = 2\n",
    "params.steps = 1\n",
    "params.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(params.optimizer, params.steps)\n",
    "\n",
    "# Dataloader\n",
    "data = params.train_set\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    VoltaDaUfes(data, params, False),\n",
    "    batch_size = params.mini_batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle = True\n",
    "    )\n",
    "\n",
    "# Dataloader\n",
    "data = params.val_set\n",
    "testing_dataloader = torch.utils.data.DataLoader(\n",
    "    VoltaDaUfes(data, params, False),\n",
    "    batch_size = 1,\n",
    "    shuffle = False\n",
    "    )\n",
    "\n",
    "# Start test  (params, test_loader,train_loader,)\n",
    "eng = DarknetEngine(\n",
    "    params, testing_dataloader,train_dataloader,\n",
    "    device=device\n",
    ")\n",
    "eng()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5 - Executar Treino**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train( epocas, log_interval )\n",
    "eng.train(5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6 - Executar Teste**\n",
    "resultado esperado\n",
    "MAE0\tMAE1\tMAE2\n",
    "76.7 \t96.11 \t97.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = \"/dados/ufes/deepvgl_final.weights\"\n",
    "weights = \"backup/deepvgl_5.state.pt\"\n",
    "if weights is not None:\n",
    "    if args.initial_weight.endswith('.state.pt'):\n",
    "        params.load(weights)\n",
    "    else:\n",
    "        params.network.load(weights, strict=False)\n",
    "\n",
    "eng.test()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPYsOgetbGoIiUqTJAP+d4p",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Cópia de DeepVGL-torch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}